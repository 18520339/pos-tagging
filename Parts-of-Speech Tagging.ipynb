{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import unicodedata as ud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tách từ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sử dụng thuật toán Longest Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllablize(sentence):\n",
    "    word = '\\w+'\n",
    "    non_word = '[^\\w\\s]'\n",
    "    digits = '\\d+([\\.,_]\\d+)+'\n",
    "    \n",
    "    patterns = []\n",
    "    patterns.extend([word, non_word, digits])\n",
    "    patterns = f\"({'|'.join(patterns)})\"\n",
    "    \n",
    "    sentence = ud.normalize('NFC', sentence)\n",
    "    tokens = re.findall(patterns, sentence, re.UNICODE)\n",
    "    return [token[0] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_n_grams(path):\n",
    "    with open(path, encoding='utf8') as f:\n",
    "        words = f.read()\n",
    "        words = ast.literal_eval(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_matching(sentence, bi_grams, tri_grams):\n",
    "    syllables = syllablize(sentence)\n",
    "    syl_len = len(syllables)\n",
    "    \n",
    "    curr_id = 0\n",
    "    word_list = []\n",
    "    done = False\n",
    "    \n",
    "    while (curr_id < syl_len) and (not done):\n",
    "        curr_word = syllables[curr_id]\n",
    "        if curr_id >= syl_len - 1:\n",
    "            word_list.append(curr_word)\n",
    "            done = True\n",
    "        else:\n",
    "            next_word = syllables[curr_id + 1]\n",
    "            pair_word = ' '.join([curr_word.lower(), next_word.lower()])\n",
    "            if curr_id >= (syl_len - 2):\n",
    "                if pair_word in bi_grams:\n",
    "                    word_list.append('_'.join([curr_word, next_word]))\n",
    "                    curr_id += 2\n",
    "                else:\n",
    "                    word_list.append(curr_word)\n",
    "                    curr_id += 1\n",
    "            else:\n",
    "                next_next_word = syllables[curr_id + 2]\n",
    "                triple_word = ' '.join([pair_word, next_next_word.lower()])\n",
    "                if triple_word in tri_grams:\n",
    "                    word_list.append('_'.join([curr_word, next_word, next_next_word]))\n",
    "                    curr_id += 3\n",
    "                elif pair_word in bi_grams:\n",
    "                    word_list.append('_'.join([curr_word, next_word]))\n",
    "                    curr_id += 2\n",
    "                else:\n",
    "                    word_list.append(curr_word)\n",
    "                    curr_id += 1\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nhưng', 'sự_thực', 'hiện', 'vẫn', 'còn', 'chưa', 'phù_hợp']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_grams = load_n_grams('sources/bi_grams.txt')\n",
    "tri_grams = load_n_grams('sources/tri_grams.txt')\n",
    "longest_matching('nhưng sự thực hiện vẫn còn chưa phù hợp', bi_grams, tri_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sử dụng thư viện VnCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nhưng', 'sự', 'thực_hiện', 'vẫn', 'còn', 'chưa', 'phù_hợp']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vncorenlp import VnCoreNLP\n",
    "client = VnCoreNLP(address=\"http://127.0.0.1\", port=9001)\n",
    "word_list = client.tokenize('nhưng sự thực hiện vẫn còn chưa phù hợp')\n",
    "word_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tạo ngữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng câu: 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pha lập công trên đã giúp Rashford giải hạn bàn thắng tại sân Old Trafford kéo dài 845 phút .\\n',\n",
       " 'Với 3 điểm có được trong trận đấu này , Quỷ đỏ đã leo lên vị trí thứ 2 trên bảng xếp hạng Premier League với 30 điểm , chỉ kém đội đầu bảng Liverpool 2 điểm .\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = open('sources/sentences.txt', encoding='utf-8').readlines()\n",
    "print('Số lượng câu:', len(sentences))\n",
    "sentences[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sources/tokenize.txt', 'w', encoding='utf-8') as f:\n",
    "    for sentence in sentences:\n",
    "        word_list = client.tokenize(sentence)\n",
    "        for word in word_list[0]: f.write(word + '\\n')\n",
    "        if sentence != sentences[-1]: f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ: 1006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pha\\n', 'lập_công\\n', 'trên\\n', 'đã\\n', 'giúp\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_corpus = open('sources/tokenize.txt', encoding='utf-8').readlines()\n",
    "print('Số lượng từ:', len(tokenize_corpus))\n",
    "tokenize_corpus[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(vocabs, path):\n",
    "    data = []\n",
    "    file = open(path, encoding='utf-8').readlines()\n",
    "    \n",
    "    for index, word in enumerate(file):\n",
    "        if not word.split():\n",
    "            word = '--n--'\n",
    "            data.append(word)\n",
    "            continue\n",
    "        elif word.lower().strip() not in vocabs:\n",
    "            word = '--unk--'\n",
    "            data.append(word)\n",
    "            continue\n",
    "        data.append(word.strip())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ vựng: 54934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'A', 'a_dua', 'a_ha', 'a_lô']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs = open('sources/vocabs.txt', encoding='utf-8').read().split('\\n')\n",
    "print('Số lượng từ vựng:', len(vocabs))\n",
    "vocabs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ trong tập test: 119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Những', 'ngày', 'đẹp_đẽ', 'ấy', ',']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words = preprocess(vocabs, 'test.txt')\n",
    "print('Số lượng từ trong tập test:', len(test_words))\n",
    "test_words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ trong tập gold: 119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Những\\tL\\n', 'ngày\\tN\\n', 'đẹp_đẽ\\tA\\n', 'ấy\\tP\\n', ',\\tCH\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_corpus = open('gold.txt', encoding='utf-8').readlines()\n",
    "print('Số lượng từ trong tập gold:', len(gold_corpus))\n",
    "gold_corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ trong tập train: 886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pha\\tNp\\n', 'lập_công\\tV\\n', 'trên\\tE\\n', 'đã\\tR\\n', 'giúp\\tV\\n']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus = open('train.txt', encoding='utf-8').readlines()\n",
    "print('Số lượng từ trong tập train:', len(train_corpus))\n",
    "train_corpus[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Parts of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_word_tag(word_tag, vocabs): \n",
    "    if not word_tag.split():\n",
    "        word = '--n--'\n",
    "        tag = '--s--'\n",
    "        return word, tag\n",
    "    else:\n",
    "        word, tag = word_tag.split()\n",
    "        if word.lower() not in vocabs: word = '--unk--'\n",
    "        return word, tag\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionaries(train_corpus, vocab):\n",
    "    emission_counts = defaultdict(int)\n",
    "    transition_counts = defaultdict(int)\n",
    "    tag_counts = defaultdict(int)\n",
    "    \n",
    "    prev_tag = '--s--' \n",
    "    i = 0 \n",
    "    \n",
    "    for word_tag in train_corpus:\n",
    "        i += 1\n",
    "        word, tag = seperate_word_tag(word_tag, vocab) \n",
    "        \n",
    "        transition_counts[(prev_tag, tag)] += 1\n",
    "        emission_counts[(tag, word)] += 1\n",
    "        tag_counts[tag] += 1\n",
    "        prev_tag = tag\n",
    "    return emission_counts, transition_counts, tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng nhãn: 17\n",
      "['--s--', 'A', 'C', 'CH', 'Cc', 'E', 'L', 'M', 'N', 'Nc', 'Np', 'Nu', 'P', 'R', 'T', 'V', 'Z']\n"
     ]
    }
   ],
   "source": [
    "emission_counts, transition_counts, tag_counts = create_dictionaries(train_corpus, vocabs)\n",
    "states = sorted(tag_counts.keys())\n",
    "print('Số lượng nhãn:', len(states))\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition examples: \n",
      "(('--s--', 'Np'), 19)\n",
      "(('Np', 'V'), 13)\n",
      "(('V', 'E'), 26)\n"
     ]
    }
   ],
   "source": [
    "print(\"Transition examples: \")\n",
    "for example in list(transition_counts.items())[:3]:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emission examples: \n",
      "(('V', 'thông_báo'), 1)\n",
      "(('V', 'hết'), 1)\n",
      "(('N', 'tinh_thần'), 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Emission examples: \")\n",
    "for example in list(emission_counts.items())[200:203]:\n",
    "    print (example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pos(test_words, gold_corpus, emission_counts, vocabs, states):\n",
    "    num_correct = 0\n",
    "    all_words = set(emission_counts.keys())\n",
    "    total = len(gold_corpus)\n",
    "    \n",
    "    for word, gold_tuple in zip(test_words, gold_corpus): \n",
    "        gold_tuple_list = gold_tuple.split()\n",
    "        if len(gold_tuple_list) != 2: continue\n",
    "        else: true_label = gold_tuple_list[1]\n",
    "    \n",
    "        count_final = 0\n",
    "        pos_final = ''\n",
    "        if word.lower() not in vocabs: continue\n",
    "        \n",
    "        for pos in states:\n",
    "            if (pos, word) not in emission_counts: continue\n",
    "            count = emission_counts[(pos, word)]\n",
    "            \n",
    "            if count > count_final:\n",
    "                count_final = count\n",
    "                pos_final = pos\n",
    "                    \n",
    "        if pos_final == true_label: num_correct += 1\n",
    "    accuracy = num_correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác của dự đoán: 0.4789915966386555\n"
     ]
    }
   ],
   "source": [
    "accuracy = predict_pos(test_words, gold_corpus, emission_counts, vocabs, states)\n",
    "print('Độ chính xác của dự đoán:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ma trận xác suất Hidden Markov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ma trận chuyển tiếp 'A' (transition matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transition_matrix(alpha, tag_counts, transition_counts):\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    num_tags = len(all_tags)\n",
    "    \n",
    "    A = np.zeros((num_tags, num_tags))\n",
    "    trans_keys = set(transition_counts.keys())\n",
    "    \n",
    "    for i in range(num_tags):\n",
    "        for j in range(num_tags):\n",
    "            count = 0\n",
    "            key = (all_tags[i],all_tags[j])\n",
    "            if key in transition_counts: count = transition_counts[key]\n",
    "                \n",
    "            count_prev_tag = tag_counts[all_tags[i]]\n",
    "            A[i, j] = (count + alpha) / (count_prev_tag + alpha * num_tags)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>Nc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.075753</td>\n",
       "      <td>0.075753</td>\n",
       "      <td>0.393853</td>\n",
       "      <td>0.045458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.732570</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.083316</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.124953</td>\n",
       "      <td>0.458051</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.099053</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.212252</td>\n",
       "      <td>0.009438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nc</th>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.187363</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           E         L         M         N        Nc\n",
       "E   0.000015  0.075753  0.075753  0.393853  0.045458\n",
       "L   0.000067  0.000067  0.000067  0.732570  0.000067\n",
       "M   0.083316  0.000042  0.124953  0.458051  0.000042\n",
       "N   0.099053  0.000005  0.018871  0.212252  0.009438\n",
       "Nc  0.000062  0.000062  0.000062  0.187363  0.000062"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.001\n",
    "A = create_transition_matrix(alpha, tag_counts, transition_counts)\n",
    "df = pd.DataFrame(\n",
    "    A[5:10, 5:10], \n",
    "    index = states[5:10], \n",
    "    columns = states[5:10]\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ma trận phát xạ 'B' (emission matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emission_matrix(alpha, tag_counts, emission_counts, vocabs):\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    num_tags = len(tag_counts)\n",
    "    num_words = len(vocabs)\n",
    "    \n",
    "    B = np.zeros((num_tags, num_words))\n",
    "    emis_keys = set(list(emission_counts.keys()))\n",
    "    \n",
    "    for i in range(num_tags):\n",
    "        for j in range(num_words):\n",
    "            count = 0\n",
    "            key = (all_tags[i], vocabs[j])\n",
    "            if key in emission_counts.keys(): count = emission_counts[key]\n",
    "                \n",
    "            count_tag = tag_counts[all_tags[i]]\n",
    "            B[i, j] = (count + alpha) / (count_tag + alpha * num_words)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thông_báo</th>\n",
       "      <th>hạt_nhân</th>\n",
       "      <th>tinh_thần</th>\n",
       "      <th>lập_công</th>\n",
       "      <th>vị_trí</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>0.003654</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cc</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    thông_báo  hạt_nhân  tinh_thần  lập_công    vị_trí\n",
       "N    0.000004  0.000004   0.003750  0.000004  0.000004\n",
       "V    0.003654  0.000004   0.000004  0.003654  0.000004\n",
       "CH   0.000007  0.000007   0.000007  0.000007  0.000007\n",
       "Cc   0.000015  0.000015   0.000015  0.000015  0.000015\n",
       "E    0.000008  0.000008   0.000008  0.000008  0.000008"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cidx  = ['thông_báo', 'hạt_nhân', 'tinh_thần', 'lập_công', 'vị_trí']\n",
    "rvals = ['N', 'V', 'CH', 'Cc', 'E', 'L']\n",
    "cols = [vocabs.index(a) for a in cidx]\n",
    "rows = [states.index(a) for a in rvals]\n",
    "\n",
    "B = create_emission_matrix(alpha, tag_counts, emission_counts, list(vocabs))\n",
    "df = pd.DataFrame(B[np.ix_(rows, cols)], index=rvals, columns=cidx)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Thuật toán Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bước Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_initialize(states, tag_counts, A, B, corpus, vocabs):\n",
    "    num_tags = len(tag_counts)\n",
    "    s_idx = states.index('--s--')\n",
    "    \n",
    "    best_probs = np.zeros((num_tags, len(corpus)))\n",
    "    best_paths = np.zeros((num_tags, len(corpus)), dtype=int)\n",
    "    \n",
    "    for i in range(num_tags):\n",
    "        if A[s_idx,i] == 0: best_probs[i, 0] = float('-inf')\n",
    "        else: \n",
    "            index = vocabs.index(corpus[0].lower())\n",
    "            best_probs[i, 0] = math.log(A[s_idx, i]) + math.log(B[i, index])\n",
    "    return best_probs, best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_probs[0, 0]: -22.351433816984247\n",
      "best_paths[2, 3]: 0\n"
     ]
    }
   ],
   "source": [
    "best_probs, best_paths = viterbi_initialize(states, tag_counts, A, B, test_words, vocabs)\n",
    "print('best_probs[0, 0]:', best_probs[0, 0]) \n",
    "print('best_paths[2, 3]:', best_paths[2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bước Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_forward(A, B, corpus, best_probs, best_paths, vocabs):\n",
    "    num_tags = best_probs.shape[0]\n",
    "    \n",
    "    for i in range(1, len(corpus)): \n",
    "        if i % 5000 == 0: print(f'Processed {i} words...')\n",
    "            \n",
    "        for j in range(num_tags):\n",
    "            best_prob_i = float('-inf')\n",
    "            best_path_i = None\n",
    "            \n",
    "            for k in range(num_tags):\n",
    "                index = vocabs.index(corpus[i].lower())\n",
    "                prob = best_probs[k, i - 1] + math.log(A[k, j]) + math.log(B[j, index])\n",
    "\n",
    "                if prob > best_prob_i:\n",
    "                    best_prob_i = prob\n",
    "                    best_path_i = k\n",
    "                    \n",
    "            best_probs[j, i] = best_prob_i\n",
    "            best_paths[j, i] = best_path_i\n",
    "            \n",
    "    return best_probs, best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_probs[0, 1]: -28.208223583028193\n",
      "best_probs[0, 4]: -52.447189842755186\n"
     ]
    }
   ],
   "source": [
    "best_probs, best_paths = viterbi_forward(A, B, test_words, best_probs, best_paths, vocabs)\n",
    "print('best_probs[0, 1]:', best_probs[0, 1]) \n",
    "print('best_probs[0, 4]:', best_probs[0, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bước Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_backward(best_probs, best_paths, corpus, states):\n",
    "    m = best_paths.shape[1] \n",
    "    z = [None] * m\n",
    "    \n",
    "    num_tags = best_probs.shape[0]\n",
    "    best_prob_for_last_word = float('-inf')\n",
    "    pred = [None] * m\n",
    "    \n",
    "    for k in range(num_tags):\n",
    "        if best_probs[k,-1] > best_prob_for_last_word:\n",
    "            best_prob_for_last_word = best_probs[k, -1]\n",
    "            z[m - 1] = k\n",
    "            \n",
    "    pred[m - 1] = states[k]\n",
    "    for i in range(len(corpus) - 1, -1, -1):\n",
    "        pos_tag = best_paths[np.argmax(best_probs[:, i]), i]\n",
    "        z[i - 1] = best_paths[pos_tag, i]\n",
    "        pred[i - 1] = states[pos_tag]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự đoán cho pred[-7:118]:\n",
      "['là', 'công_cụ', 'không_thể', 'đảo_ngược', 'trong', 'cuộc_sống']\n",
      "['V', 'P', 'R', 'V', 'E', 'N']\n",
      "Dự đoán cho pred[0:7]:\n",
      "['Những', 'ngày', 'đẹp_đẽ', 'ấy', ',', 'bố', 'luôn']\n",
      "['L', 'N', 'CH', 'Nu', 'CH', 'P', 'R']\n"
     ]
    }
   ],
   "source": [
    "pred = viterbi_backward(best_probs, best_paths, test_words, states)\n",
    "m = len(pred)\n",
    "\n",
    "print(f'Dự đoán cho pred[-7:{m - 1}]:')\n",
    "print(test_words[-7:m-1])\n",
    "print(pred[-7:m-1])\n",
    "\n",
    "print('Dự đoán cho pred[0:7]:')\n",
    "print(test_words[0:7])\n",
    "print(pred[0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(sentence):\n",
    "    output = ''\n",
    "    for word in sentence.split():\n",
    "        if word not in test_words: word = '--unk--'\n",
    "        index = test_words.index(word)\n",
    "        output += f'{word}/{pred[index]} '\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Những/L ngày/N đẹp_đẽ/CH ấy/Nu ,/CH bố/P luôn/R dành/V thời_gian/N để/E vui_vẻ/N với/E anh_em/Nc tôi/P ./CH\n",
      "Trong/E khi/N chờ/E nước/N nóng/A ,/CH tôi/P pha/V rượu/N táo/CH nóng/A ./CH\n",
      "Hàng/N trăm/M người/N đến/V dùng/V tiệc/CH tự/--s-- chọn/Np ở/E chỗ/CH mẹ/E những/L ngày/N Giáng_sinh/A ./CH\n",
      "Năm/N nào/V cũng/R vậy/A hoặc/Cc --unk--/N --unk--/N ./CH\n",
      "Tôi/P chưa/CH bao_giờ/--s-- thực_sự/Np --unk--/N mệt_mỏi/CH vì/--s-- nó/P ./CH\n",
      "Tôi/P đã/R có_thể/V chống/P lại/R cảm_giác/V đó/V trong/E nhiều/A năm/N qua/V ./CH\n",
      "Những/L năm/N gần/CH đây/--s-- tôi/P qua_lại/CH sân_bay/--s-- --unk--/N thường_xuyên/N ./CH\n",
      "Trường/N tôi/P từng/CH nghiêm_cấm/--s-- sử_dụng/N điện_thoại/V trong/E lớp/N ./CH\n",
      "Học_sinh/Np ngày_nay/R có_thể/V dễ_dàng/CH tiếp_cận/--s-- bài_học/Nc và/Cc phương_pháp/L giải/N bài_tập/A ./CH\n",
      "Điện_thoại/Np thông_minh/R là/V công_cụ/P không_thể/R đảo_ngược/V trong/E cuộc_sống/N ./CH\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences[50:]:\n",
    "    word_list = client.tokenize(sentence)\n",
    "    print(predict_sentence(' '.join(word_list[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đánh giá thuật toán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for prediction, word_tag in zip(pred, gold_corpus):\n",
    "    word_tag_tuple = word_tag.split()\n",
    "    if len(word_tag_tuple) != 2: continue \n",
    "\n",
    "    word, tag = word_tag_tuple\n",
    "    y_pred.append(prediction)\n",
    "    y_true.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả của mô hình Hidden Markov kết hợp thuật toán Viterbi:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       --s--       0.00      0.00      0.00         8\n",
      "           A       0.20      0.40      0.27         5\n",
      "           C       0.00      0.00      0.00         0\n",
      "          CH       0.92      0.52      0.67        21\n",
      "          Cc       1.00      1.00      1.00         2\n",
      "           E       0.88      0.78      0.82         9\n",
      "           L       1.00      0.75      0.86         4\n",
      "           M       1.00      1.00      1.00         1\n",
      "           N       0.48      0.62      0.54        21\n",
      "          Nc       0.33      0.50      0.40         2\n",
      "          Np       0.00      0.00      0.00         5\n",
      "          Nu       0.00      0.00      0.00         2\n",
      "           P       0.50      0.70      0.58        10\n",
      "           R       0.71      0.71      0.71         7\n",
      "           V       0.45      0.69      0.55        13\n",
      "\n",
      "    accuracy                           0.55       110\n",
      "   macro avg       0.50      0.51      0.49       110\n",
      "weighted avg       0.56      0.55      0.54       110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('Kết quả của mô hình Hidden Markov kết hợp thuật toán Viterbi:\\n')\n",
    "print(classification_report(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. So sánh kết quả với VnCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Những/L ngày/N đẹp_đẽ/A ấy/P ,/CH bố/N luôn/R dành/V thời_gian/N để/E vui_vẻ/A với/E anh_em/N tôi/P ./CH \n",
      "Trong/E khi/N chờ/V nước/N nóng/A ,/CH tôi/P pha/V rượu/N táo/V nóng/A ./CH \n",
      "Hàng/N trăm/M người/N đến/V dùng/V tiệc/N tự/P chọn/V ở/E chỗ/N mẹ/N những/L ngày/N Giáng_sinh/Np ./CH \n",
      "Năm/Np nào/P cũng/R vậy/P hoặc/Cc có_vẻ/X như_vậy/X ./CH \n",
      "Tôi/P chưa/R bao_giờ/P thực_sự/A cảm_thấy/V mệt_mỏi/A vì/E nó/P ./CH \n",
      "Tôi/P đã/R có_thể/R chống/V lại/R cảm_giác/N đó/P trong/E nhiều/A năm/N qua/V ./CH \n",
      "Những/L năm/N gần/A đây/P tôi/P qua_lại/V sân_bay/N Tân_Sơn_Nhất/Np thường_xuyên/A ./CH \n",
      "Trường/Np tôi/P từng/P nghiêm_cấm/V sử_dụng/V điện_thoại/N trong/E lớp/N ./CH \n",
      "Học_sinh/N ngày_nay/N có_thể/R dễ_dàng/A tiếp_cận/V bài_học/N và/Cc phương_pháp/N giải/N bài_tập/N ./CH \n",
      "Điện_thoại/N thông_minh/A là/V công_cụ/N không_thể/R đảo_ngược/V trong/E cuộc_sống/N ./CH "
     ]
    }
   ],
   "source": [
    "y_pred_lib = []\n",
    "\n",
    "for word_tag in gold_corpus:\n",
    "    word_tag_tuple = word_tag.split()\n",
    "    if len(word_tag_tuple) != 2: \n",
    "        print()\n",
    "        continue \n",
    "        \n",
    "    word, tag = word_tag_tuple\n",
    "    if '_' not in word: pred = client.pos_tag(word)\n",
    "    else: pred = client.pos_tag(word.replace('_', ' '))\n",
    "    \n",
    "    print(f'{word}/{pred[0][0][1]}', end=' ') \n",
    "    y_pred_lib.append(pred[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả khi sử dụng thư viện VnCoreNLP:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.90      0.82      0.86        11\n",
      "           C       0.00      0.00      0.00         0\n",
      "          CH       1.00      1.00      1.00        12\n",
      "          Cc       1.00      1.00      1.00         2\n",
      "           E       1.00      1.00      1.00         8\n",
      "           L       1.00      1.00      1.00         3\n",
      "           M       1.00      1.00      1.00         1\n",
      "           N       0.85      0.82      0.84        28\n",
      "          Nc       0.00      0.00      0.00         0\n",
      "          Np       1.00      0.50      0.67         4\n",
      "           P       1.00      0.93      0.97        15\n",
      "           R       0.86      0.75      0.80         8\n",
      "           V       0.65      0.81      0.72        16\n",
      "           X       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85       110\n",
      "   macro avg       0.73      0.69      0.70       110\n",
      "weighted avg       0.87      0.85      0.85       110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Kết quả khi sử dụng thư viện VnCoreNLP:\\n')\n",
    "print(classification_report(y_pred_lib, y_true))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
