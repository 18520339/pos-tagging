{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordnlp.server import CoreNLPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = CoreNLPClient(start_server=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punct = set(string.punctuation)\n",
    "noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
    "verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
    "adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
    "adv_suffix = [\"ward\", \"wards\", \"wise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_unknown(word):\n",
    "    if any(char.isdigit() for char in word):\n",
    "        return 'unk_digit'\n",
    "    elif any(char in punct for char in word):\n",
    "        return 'unk_punct'\n",
    "    elif any(char.isupper() for char in word):\n",
    "        return 'unk_upper'\n",
    "    elif any(word.endswith(suffix) for suffix in noun_suffix):\n",
    "        return 'unk_noun'\n",
    "    elif any(word.endswith(suffix) for suffix in verb_suffix):\n",
    "        return 'unk_verb'\n",
    "    elif any(word.endswith(suffix) for suffix in adj_suffix):\n",
    "        return 'unk_adj'\n",
    "    elif any(word.endswith(suffix) for suffix in adv_suffix):\n",
    "        return 'unk_adv'\n",
    "    return 'unk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(vocab, path):\n",
    "    data = []\n",
    "    file = open(path).readlines()\n",
    "    \n",
    "    for index, word in enumerate(file):\n",
    "        if not word.split():\n",
    "            word = '--n--'\n",
    "            data.append(word)\n",
    "            continue\n",
    "        elif word.strip() not in vocab:\n",
    "            word = assign_unknown(word)\n",
    "            data.append(word)\n",
    "            continue\n",
    "        data.append(word.strip())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocabs: 23777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['!', '#', '$', '%', '&']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = open('vocab.txt').read().split('\\n')\n",
    "print('Number of vocabs:', len(vocab))\n",
    "vocab[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test words: 34199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The', 'economy', \"'s\", 'temperature', 'will']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words = preprocess(vocab, 'test.txt')\n",
    "print('Number of test words:', len(test_words))\n",
    "test_words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code chia file test\n",
    "with open('quan_test.txt', 'w') as quan:\n",
    "    with open('anh_test.txt', 'w') as anh:\n",
    "        with open('gold.txt') as root:\n",
    "            i = 1\n",
    "            for r in root.readlines():\n",
    "                if i <= 60:\n",
    "                    quan.write(r)\n",
    "                else:\n",
    "                    anh.write(r)\n",
    "                if r == '.\\t.\\n':\n",
    "                    i += 1\n",
    "                    if i > 120:\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gold words: 1596\n"
     ]
    }
   ],
   "source": [
    "test_ = open('anh_test.txt').readlines()\n",
    "print('Number of gold words:', len(test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_word_tag(word_tag, vocab): \n",
    "    if not word_tag.split():\n",
    "        word = '--n--'\n",
    "        tag = '--s--'\n",
    "        return word, tag\n",
    "    else:\n",
    "        word, tag = word_tag.split()\n",
    "        if word not in vocab: \n",
    "            word = assign_unknown(word)\n",
    "        return word, tag\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code tách từ và tag ra riêng\n",
    "word = []\n",
    "tag_true = []\n",
    "for word_tag in test_:\n",
    "    w, t = seperate_word_tag(word_tag, vocab) \n",
    "    word.append(w)\n",
    "    tag_true.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hàm tính độ chính xác input tag_true, tag_pre => accuracy\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "def evaluate(tag_true, tag_pre):\n",
    "    precision = precision_score(tag_true, tag_pre, average='micro')\n",
    "    recal = recall_score(tag_true, tag_pre, average='micro')\n",
    "    accuracy = accuracy_score(tag_true, tag_pre)\n",
    "    return precision, recal, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_lib(sentence_test):\n",
    "    tag_pre = []\n",
    "    for sentence in sentence_test:\n",
    "        ann = client.annotate(sentence, annotators=['pos'])\n",
    "        sent = ann.sentence[0]\n",
    "        token = sent.token\n",
    "        tag_pre.append(token[0].pos)\n",
    "    return tag_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_pre = predict_from_lib(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.845\n",
      "Recal: 0.845\n",
      "Accuracy: 0.845\n"
     ]
    }
   ],
   "source": [
    "precision, recal, accuracy = evaluate(tag_pre, tag_true)\n",
    "print('Precision: %.3f' % precision)\n",
    "print('Recal: %.3f' % recal)\n",
    "print('Accuracy: %.3f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_output(sentence):\n",
    "    output = ''\n",
    "    for word in sentence.split():\n",
    "        ann = client.annotate(sentence, annotators=['pos'])\n",
    "        sent = ann.sentence[0]\n",
    "        token = sent.token\n",
    "        output += word + '/' + token[0].pos + ' '\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i/PRP love/PRP you/PRP'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#demo output\n",
    "a = 'i love you'\n",
    "demo_output(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
